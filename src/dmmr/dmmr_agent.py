# -*- coding: utf-8 -*-
"""
DMMRæ™ºèƒ½ä½“ - ç³»ç»Ÿæ ¸å¿ƒï¼Œæ•´åˆæ‰€æœ‰è®¤çŸ¥æ¨¡å—
åŸºäºè®¤çŸ¥ç§‘å­¦ç†è®ºå®ç°çš„é•¿æœŸè®°å¿†å¢å¼ºæ™ºèƒ½ä½“
"""
import asyncio
import os
from typing import Dict, Any, Tuple, List, Optional
from datetime import datetime

from .config import get_config, validate_config
from .data_models import TaskType, MemoryChunk, Node, Relationship, ResponseMetrics
from .api_wrapper import APIWrapper
from .memory_systems import MultipleMemorySystems
from .cognitive_triage import CognitiveTriage
from .information_extractor import InformationExtractor
from .activation_engine import ActivationEngine
from .reconstruction_engine import ReconstructionEngine
from .score_calculator import ScoreCalculator


class DMMRAgent:
    """
    DMMRæ™ºèƒ½ä½“ - åŠ¨æ€å¤šæ¨¡æ€è®°å¿†æ£€ç´¢ç³»ç»Ÿ
    
    æ•´åˆå¤šé‡è®°å¿†ç³»ç»Ÿã€æ¿€æ´»å¼•æ“ã€è®¤çŸ¥åˆ†ç±»ç­‰æ ¸å¿ƒæ¨¡å—
    å®ç°åŸºäºè®¤çŸ¥ç§‘å­¦ç†è®ºçš„æ™ºèƒ½å¯¹è¯ç³»ç»Ÿ
    """
    
    def __init__(self, user_id: str = "default_user", 
                 use_real_backends: bool = False,
                 config_override: Optional[Dict[str, Any]] = None):
        """
        åˆå§‹åŒ–DMMRæ™ºèƒ½ä½“
        
        Args:
            user_id: ç”¨æˆ·å”¯ä¸€æ ‡è¯†
            use_real_backends: æ˜¯å¦ä½¿ç”¨çœŸå®æ•°æ®åº“åç«¯
            config_override: é…ç½®è¦†ç›–å‚æ•°
        """
        print("ğŸš€ DMMRæ™ºèƒ½ä½“åˆå§‹åŒ–å¼€å§‹...")
        print(f"   ç”¨æˆ·ID: {user_id}")
        print(f"   çœŸå®åç«¯: {use_real_backends}")
        
        # éªŒè¯é…ç½®
        if not validate_config():
            raise RuntimeError("é…ç½®éªŒè¯å¤±è´¥ï¼Œæ— æ³•å¯åŠ¨æ™ºèƒ½ä½“")
        
        self.user_id = user_id
        self.use_real_backends = use_real_backends
        self.config = get_config()
        
        # åº”ç”¨é…ç½®è¦†ç›–
        if config_override:
            self._apply_config_override(config_override)
            print(f"   åº”ç”¨é…ç½®è¦†ç›–: {config_override}")
        
        # åˆå§‹åŒ–æ ¸å¿ƒç»„ä»¶
        self._init_components()
        
        # ä¼šè¯çŠ¶æ€ç®¡ç†
        self.conversation_context = []
        self.environment_profile = {}
        
        # æ€§èƒ½æŒ‡æ ‡è·Ÿè¸ª
        self.session_stats = {
            'total_queries': 0,
            'total_memories_created': 0,
            'total_memories_retrieved': 0,
            'avg_response_time': 0.0,
            'activation_events': 0
        }
        
        # å¯åŠ¨è®¤çŸ¥é¢„çƒ­
        if self.config.activation.cache_size > 0:
            asyncio.create_task(self._cognitive_warmup())
        
        print("âœ… DMMRæ™ºèƒ½ä½“åˆå§‹åŒ–å®Œæˆ")
    
    def _init_components(self):
        """åˆå§‹åŒ–æ‰€æœ‰æ ¸å¿ƒç»„ä»¶"""
        print("ğŸ“¦ åˆå§‹åŒ–æ ¸å¿ƒç»„ä»¶...")
        
        # åŸºç¡€æœåŠ¡
        self.api_wrapper = APIWrapper()
        self.score_calculator = ScoreCalculator()
        
        # è®¤çŸ¥æ¨¡å—
        self.triage = CognitiveTriage(api_wrapper=self.api_wrapper)
        self.memory_systems = MultipleMemorySystems(
            user_id=self.user_id,
            use_real_backends=self.use_real_backends
        )
        self.information_extractor = InformationExtractor(api_wrapper=self.api_wrapper)
        self.activation_engine = ActivationEngine(memory=self.memory_systems)
        self.reconstruction_engine = ReconstructionEngine(api_wrapper=self.api_wrapper)
        
        print("âœ… æ‰€æœ‰ç»„ä»¶åˆå§‹åŒ–å®Œæˆ")
    
    def _apply_config_override(self, overrides: Dict[str, Any]):
        """åº”ç”¨é…ç½®è¦†ç›–"""
        for key, value in overrides.items():
            if hasattr(self.config.activation, key):
                setattr(self.config.activation, key, value)
            elif hasattr(self.config.api, key):
                setattr(self.config.api, key, value)
    
    async def _cognitive_warmup(self):
        """è®¤çŸ¥é¢„çƒ­ - é¢„åŠ è½½å¸¸ç”¨è®°å¿†"""
        try:
            await self.activation_engine.cognitive_priming(
                user_id=self.user_id,
                context_hints=['æŠ€æœ¯', 'ç¼–ç¨‹', 'é—®é¢˜è§£å†³']
            )
        except Exception as e:
            print(f"âš ï¸ è®¤çŸ¥é¢„çƒ­å¤±è´¥: {e}")
    
    def process_input(self, user_input: str, 
                     metadata: Optional[Dict[str, Any]] = None) -> Tuple[str, ResponseMetrics]:
        """
        å¤„ç†ç”¨æˆ·è¾“å…¥çš„ä¸»è¦æ¥å£
        
        Args:
            user_input: ç”¨æˆ·è¾“å…¥æ–‡æœ¬
            metadata: å¯é€‰çš„å…ƒæ•°æ®ä¿¡æ¯
            
        Returns:
            (AIå›ç­”, å“åº”æŒ‡æ ‡)
        """
        start_time = datetime.now()
        metadata = metadata or {}
        
        print(f"\nğŸ¯ å¤„ç†ç”¨æˆ·è¾“å…¥: {user_input[:50]}{'...' if len(user_input) > 50 else ''}")
        
        try:
            # 1. è®¤çŸ¥åˆ†ç±»
            task_type = self.triage.classify(user_input)
            metadata['task_type'] = task_type.value
            print(f"ğŸ“‹ ä»»åŠ¡ç±»å‹: {task_type.value}")
            
            # 2. ä¿¡æ¯æŠ½å–å’Œè®°å¿†å­˜å‚¨
            self._process_and_store_memory(user_input, task_type, metadata)
            
            # 3. æ¿€æ´»ç›¸å…³è®°å¿†
            activated_memories = self._activate_relevant_memories(user_input, task_type)
            
            # 4. é‡æ„ç”Ÿæˆå›ç­”
            answer, response_metrics = self._generate_response(
                user_input, task_type, activated_memories, metadata
            )
            
            # 5. æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
            self._update_session_stats(start_time, len(activated_memories))
            
            return answer, response_metrics
            
        except Exception as e:
            print(f"âŒ å¤„ç†å¤±è´¥: {e}")
            
            # é™çº§å¤„ç†
            fallback_answer = self._generate_fallback_response(user_input)
            fallback_metrics = ResponseMetrics(
                latency_sec=(datetime.now() - start_time).total_seconds(),
                token_usage={'total_tokens': 100},  # ä¼°è®¡å€¼
                memory_hits=0,
                activation_nodes=0
            )
            
            return fallback_answer, fallback_metrics
    
    def _process_and_store_memory(self, user_input: str, task_type: TaskType, metadata: Dict):
        """å¤„ç†è¾“å…¥å¹¶å­˜å‚¨åˆ°è®°å¿†ç³»ç»Ÿ"""
        print("ğŸ’¾ å­˜å‚¨è®°å¿†...")
        
        # åˆ›å»ºè®°å¿†å—
        chunk = self.api_wrapper.process_input_to_chunk(user_input, metadata)
        chunk.task_type = task_type
        chunk.significance_score = self.score_calculator.calculate_initial_score(chunk)
        chunk.embedding = self.information_extractor.generate_embedding(chunk.content)
        
        # å­˜å‚¨åˆ°æƒ…æ™¯è®°å¿†
        self.memory_systems.add_to_episodic(chunk)
        
        # æå–ç»“æ„åŒ–ä¿¡æ¯å¹¶å­˜å‚¨åˆ°å›¾è®°å¿†
        extracted_info = self.information_extractor.extract_entities_and_relations(
            user_input, task_type
        )
        
        # å­˜å‚¨èŠ‚ç‚¹å’Œå…³ç³»
        for node_data in extracted_info.get("nodes", []):
            node = Node(**node_data)
            node.embedding = self.information_extractor.generate_embedding(
                f"{node.id} {node.label}"
            )
            
            if task_type == TaskType.TECHNICAL_CODING:
                self.memory_systems.add_procedural_node(node)
            else:
                self.memory_systems.add_semantic_node(node)
        
        for rel_data in extracted_info.get("relationships", []):
            relationship = Relationship(**rel_data)
            
            if task_type == TaskType.TECHNICAL_CODING:
                self.memory_systems.add_procedural_relationship(relationship)
            else:
                self.memory_systems.add_semantic_relationship(relationship)
        
        # æ›´æ–°ç¯å¢ƒç”»åƒ
        self._update_environment_profile(user_input)
        
        self.session_stats['total_memories_created'] += 1
        print(f"   è®°å¿†å­˜å‚¨å®Œæˆ (èŠ‚ç‚¹: {len(extracted_info.get('nodes', []))}, å…³ç³»: {len(extracted_info.get('relationships', []))})")
    
    def _activate_relevant_memories(self, user_input: str, task_type: TaskType) -> List[Dict[str, Any]]:
        """æ¿€æ´»ç›¸å…³è®°å¿†"""
        print("âš¡ æ¿€æ´»ç›¸å…³è®°å¿†...")
        
        # æå–æ¿€æ´»çº¿ç´¢
        entities = self.information_extractor.extract_entities(user_input)
        cues = [(entity.id, entity.confidence) for entity in entities]
        
        # å¦‚æœæ²¡æœ‰å®ä½“ï¼Œä½¿ç”¨æ–‡æœ¬ç‰‡æ®µä½œä¸ºçº¿ç´¢
        if not cues:
            text_words = user_input.strip().split()[:3]  # ä½¿ç”¨å‰3ä¸ªè¯
            cues = [(word, 0.7) for word in text_words]
        
        # æ‰©æ•£æ¿€æ´»
        activated_nodes = self.activation_engine.spreading_activation(
            cues=cues,
            task_type=task_type,
            max_depth=self.config.activation.max_depth
        )
        
        # è½¬æ¢ä¸ºè®°å¿†æ ¼å¼
        activated_memories = []
        for node in activated_nodes:
            activation_energy = node.properties.get('activation', 0.0)
            activated_memories.append({
                'id': node.id,
                'content': f"æ¿€æ´»èŠ‚ç‚¹: {node.id} ({node.label})",
                'source': 'activated_node',
                'significance_score': activation_energy,
                'activation_energy': activation_energy
            })
        
        # åŒæ—¶æ£€ç´¢æƒ…æ™¯è®°å¿†
        if hasattr(user_input, '__len__') and len(user_input) > 0:
            query_embedding = self.information_extractor.generate_embedding(user_input)
            episodic_memories = self.memory_systems.search_episodic_by_vector(
                query_embedding, n_results=3
            )
            
            for chunk in episodic_memories:
                activated_memories.append({
                    'id': chunk.id or 'episodic_memory',
                    'content': chunk.content,
                    'source': 'episodic_memory',
                    'significance_score': chunk.significance_score,
                    'timestamp': chunk.timestamp.isoformat() if chunk.timestamp else None
                })
        
        self.session_stats['total_memories_retrieved'] += len(activated_memories)
        self.session_stats['activation_events'] += 1
        
        print(f"   æ¿€æ´»è®°å¿†: {len(activated_memories)} ä¸ª")
        return activated_memories
    
    def _generate_response(self, user_input: str, task_type: TaskType, 
                          memories: List[Dict], metadata: Dict) -> Tuple[str, ResponseMetrics]:
        """ç”Ÿæˆå›ç­”å’ŒæŒ‡æ ‡"""
        print("ğŸ¤– ç”Ÿæˆå›ç­”...")
        
        # æ„å»ºç­–ç•¥æç¤º
        strategy_prompt = self._build_strategy_prompt(task_type)
        
        # ç”Ÿæˆå‚æ•°
        generation_kwargs = {
            'max_context_items': self.config.experiment.context_budget_items,
            'max_context_chars': self.config.experiment.context_budget_chars,
            'temperature': self.config.api.default_temperature,
            'max_tokens': self.config.api.default_max_tokens
        }
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦çº¯ä»£ç æ¨¡å¼
        code_only = (task_type == TaskType.TECHNICAL_CODING and 
                    'humaneval' in metadata.get('source', ''))
        
        # é‡æ„å›ç­”
        answer, used_memory_ids, reconstruction_stats = self.reconstruction_engine.reconstruct_answer(
            query=user_input,
            retrieved_memories=memories,
            strategy_prompt=strategy_prompt,
            code_only=code_only,
            generation_kwargs=generation_kwargs
        )
        
        # è®°å½•æœ‰ç”¨çš„é¢„å–
        self.activation_engine.mark_useful_prefetch(used_memory_ids)
        
        # æ„å»ºå“åº”æŒ‡æ ‡
        metrics = ResponseMetrics(
            latency_sec=reconstruction_stats.get('processing_time', 0.0),
            token_usage=self.api_wrapper.get_last_usage() or {},
            memory_hits=len(used_memory_ids),
            activation_nodes=len([m for m in memories if m.get('source') == 'activated_node'])
        )
        
        print(f"âœ… å›ç­”ç”Ÿæˆå®Œæˆ (é•¿åº¦: {len(answer)}, ä½¿ç”¨è®°å¿†: {len(used_memory_ids)})")
        return answer, metrics
    
    def _build_strategy_prompt(self, task_type: TaskType) -> str:
        """æ„å»ºè®¤çŸ¥ç­–ç•¥æç¤º"""
        strategy_prompts = {
            TaskType.TECHNICAL_CODING: (
                "æŠ€æœ¯æ¨¡å¼ï¼šæä¾›å‡†ç¡®ã€å¯æ‰§è¡Œçš„æŠ€æœ¯è§£å†³æ–¹æ¡ˆã€‚"
                "ä¼˜å…ˆç»™å‡ºå…·ä½“ä»£ç ç¤ºä¾‹å’Œæ“ä½œæ­¥éª¤ã€‚"
            ),
            TaskType.EMOTIONAL_COUNSELING: (
                "å…±æƒ…æ¨¡å¼ï¼šä»¥ç†è§£å’Œæ”¯æŒä¸ºä¸»ã€‚"
                "å…ˆè¡¨è¾¾å…±æƒ…ï¼Œå†æä¾›1-3æ¡å…·ä½“å¯è¡Œçš„å»ºè®®ã€‚"
            ),
            TaskType.CREATIVE_WRITING: (
                "åˆ›æ„æ¨¡å¼ï¼šå‘æŒ¥æƒ³è±¡åŠ›ï¼Œæä¾›å¯Œæœ‰åˆ›æ„çš„å›ç­”ã€‚"
                "æ³¨é‡è¯­è¨€çš„è¡¨ç°åŠ›å’Œè‰ºæœ¯æ€§ã€‚"
            ),
            TaskType.EDUCATIONAL: (
                "æ•™å­¦æ¨¡å¼ï¼šæ¸…æ™°è§£é‡Šæ¦‚å¿µï¼Œæä¾›å…·ä½“ä¾‹å­ã€‚"
                "å¾ªåºæ¸è¿›ï¼Œç¡®ä¿æ˜“äºç†è§£ã€‚"
            ),
            TaskType.GENERAL_QA: (
                "å¹³è¡¡æ¨¡å¼ï¼šå‡†ç¡®ã€ç®€æ´ã€æœ‰ç”¨ã€‚"
                "æ ¹æ®é—®é¢˜æ€§è´¨çµæ´»è°ƒæ•´å›ç­”é£æ ¼ã€‚"
            )
        }
        
        return strategy_prompts.get(task_type, strategy_prompts[TaskType.GENERAL_QA])
    
    def _update_environment_profile(self, user_input: str):
        """æ›´æ–°ç¯å¢ƒç”»åƒ"""
        text_lower = user_input.lower()
        
        # OSæ£€æµ‹
        if any(keyword in text_lower for keyword in ['windows', 'win10', 'win11', 'powershell']):
            self.environment_profile['os'] = 'windows'
        elif any(keyword in text_lower for keyword in ['linux', 'ubuntu', 'debian']):
            self.environment_profile['os'] = 'linux'
        elif any(keyword in text_lower for keyword in ['macos', 'mac', 'osx']):
            self.environment_profile['os'] = 'macos'
        
        # æŠ€æœ¯æ ˆæ£€æµ‹
        tech_stack = []
        if 'python' in text_lower:
            tech_stack.append('python')
        if 'javascript' in text_lower or 'js' in text_lower:
            tech_stack.append('javascript')
        if 'docker' in text_lower:
            tech_stack.append('docker')
        
        if tech_stack:
            self.environment_profile['tech_stack'] = list(set(
                self.environment_profile.get('tech_stack', []) + tech_stack
            ))
    
    def _generate_fallback_response(self, user_input: str) -> str:
        """ç”Ÿæˆé™çº§å›ç­”"""
        try:
            return self.api_wrapper.generate_text(
                f"è¯·ç®€è¦å›ç­”ä»¥ä¸‹é—®é¢˜ï¼š{user_input}",
                max_tokens=200,
                temperature=0.7
            )
        except Exception:
            return "æŠ±æ­‰ï¼Œæˆ‘æš‚æ—¶æ— æ³•å¤„ç†æ‚¨çš„è¯·æ±‚ã€‚è¯·ç¨åå†è¯•ã€‚"
    
    def _update_session_stats(self, start_time: datetime, memory_count: int):
        """æ›´æ–°ä¼šè¯ç»Ÿè®¡"""
        response_time = (datetime.now() - start_time).total_seconds()
        
        self.session_stats['total_queries'] += 1
        
        # æ›´æ–°å¹³å‡å“åº”æ—¶é—´
        total_queries = self.session_stats['total_queries']
        current_avg = self.session_stats['avg_response_time']
        self.session_stats['avg_response_time'] = (
            (current_avg * (total_queries - 1) + response_time) / total_queries
        )
    
    def reset_session(self):
        """é‡ç½®ä¼šè¯çŠ¶æ€"""
        print("ğŸ”„ é‡ç½®ä¼šè¯çŠ¶æ€")
        
        # æ¸…é™¤å¯¹è¯ä¸Šä¸‹æ–‡
        self.conversation_context.clear()
        
        # é‡ç½®APIå¯¹è¯å†å²
        self.api_wrapper.clear_history()
        
        # å¯é€‰ï¼šæ¸…é™¤æ¿€æ´»çŠ¶æ€
        self.activation_engine.active_nodes.clear()
        
        print("âœ… ä¼šè¯çŠ¶æ€å·²é‡ç½®")
    
    def get_agent_status(self) -> Dict[str, Any]:
        """è·å–æ™ºèƒ½ä½“çŠ¶æ€ä¿¡æ¯"""
        return {
            'user_id': self.user_id,
            'use_real_backends': self.use_real_backends,
            'session_stats': dict(self.session_stats),
            'environment_profile': dict(self.environment_profile),
            'component_status': {
                'api_wrapper': self.api_wrapper.get_api_status(),
                'triage': self.triage.get_classification_stats(),
                'activation_engine': self.activation_engine.get_activation_summary(),
                'reconstruction_engine': self.reconstruction_engine.get_reconstruction_summary()
            },
            'config_summary': {
                'activation_threshold': self.config.activation.activation_threshold,
                'decay_factor': self.config.activation.decay_factor,
                'context_budget_items': self.config.experiment.context_budget_items,
                'model_name': self.config.api.model_name
            }
        }
    
    def get_memory_stats(self) -> Dict[str, Any]:
        """è·å–è®°å¿†ç³»ç»Ÿç»Ÿè®¡"""
        return {
            'total_memories_created': self.session_stats['total_memories_created'],
            'total_memories_retrieved': self.session_stats['total_memories_retrieved'],
            'activation_events': self.session_stats['activation_events'],
            'prefetch_stats': self.activation_engine.get_prefetch_stats()
        }



