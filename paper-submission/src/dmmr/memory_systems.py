# -*- coding: utf-8 -*-
"""
å¤šé‡è®°å¿†ç³»ç»Ÿ - å®ç°æƒ…æ™¯ã€è¯­ä¹‰ã€ç¨‹åºè®°å¿†çš„ç®¡ç†
æ”¯æŒå‘é‡æ•°æ®åº“å’Œå›¾æ•°æ®åº“çš„çœŸå®/æ¨¡æ‹Ÿåç«¯
"""
import math
from typing import List, Dict, Any, Optional, Tuple
from .data_models import MemoryChunk, Node, Relationship
from .config import get_config

# å¯é€‰ä¾èµ–
try:
    import faiss
    import numpy as np
    FAISS_AVAILABLE = True
except ImportError:
    FAISS_AVAILABLE = False

try:
    from neo4j import GraphDatabase, Driver
    NEO4J_AVAILABLE = True
except ImportError:
    NEO4J_AVAILABLE = False


class VectorDatabase:
    """å‘é‡æ•°æ®åº“æ¥å£ - æ”¯æŒFAISSå’Œå†…å­˜å®ç°"""
    
    def __init__(self, collection_name: str, use_real_backend: bool = False):
        self.collection_name = collection_name
        self.use_real_backend = use_real_backend
        self.config = get_config().database
        
        if use_real_backend and FAISS_AVAILABLE:
            self._init_faiss()
        else:
            self._init_memory_backend()
    
    def _init_faiss(self):
        """åˆå§‹åŒ–FAISSåç«¯"""
        self.dim = self.config.vector_dim
        self.index = faiss.IndexFlatIP(self.dim)  # å†…ç§¯ç´¢å¼•
        self.id_to_chunk = {}
        self.chunk_ids = []
        print(f"ğŸ“Š FAISSå‘é‡æ•°æ®åº“åˆå§‹åŒ–å®Œæˆ (ç»´åº¦: {self.dim})")
    
    def _init_memory_backend(self):
        """åˆå§‹åŒ–å†…å­˜åç«¯"""
        self.memory_store = {}
        self.dim = get_config().database.vector_dim
        print(f"ğŸ’¾ å†…å­˜å‘é‡æ•°æ®åº“åˆå§‹åŒ–å®Œæˆ (é›†åˆ: {self.collection_name})")
    
    def add(self, chunk: MemoryChunk):
        """æ·»åŠ è®°å¿†å—"""
        # ç¡®ä¿æœ‰å‘é‡è¡¨ç¤º
        if chunk.embedding is None:
            chunk.embedding = self._generate_embedding(chunk.content)
        
        if hasattr(self, 'index'):  # FAISSåç«¯
            self._add_to_faiss(chunk)
        else:  # å†…å­˜åç«¯
            self._add_to_memory(chunk)
    
    def search(self, query_vector: List[float], n_results: int = 5) -> List[MemoryChunk]:
        """å‘é‡æœç´¢"""
        if hasattr(self, 'index'):
            return self._search_faiss(query_vector, n_results)
        else:
            return self._search_memory(query_vector, n_results)
    
    def _add_to_faiss(self, chunk: MemoryChunk):
        """æ·»åŠ åˆ°FAISSç´¢å¼•"""
        vector = np.array(chunk.embedding, dtype='float32').reshape(1, -1)
        self.index.add(vector)
        
        chunk_id = chunk.id or f"chunk_{len(self.chunk_ids)}"
        self.chunk_ids.append(chunk_id)
        self.id_to_chunk[chunk_id] = chunk
    
    def _add_to_memory(self, chunk: MemoryChunk):
        """æ·»åŠ åˆ°å†…å­˜å­˜å‚¨"""
        chunk_id = chunk.id or f"chunk_{len(self.memory_store)}"
        self.memory_store[chunk_id] = chunk
    
    def _search_faiss(self, query_vector: List[float], n_results: int) -> List[MemoryChunk]:
        """FAISSæœç´¢"""
        if self.index.ntotal == 0:
            return []
        
        query = np.array(query_vector, dtype='float32').reshape(1, -1)
        scores, indices = self.index.search(query, min(n_results, self.index.ntotal))
        
        results = []
        for idx in indices[0]:
            if 0 <= idx < len(self.chunk_ids):
                chunk_id = self.chunk_ids[idx]
                chunk = self.id_to_chunk.get(chunk_id)
                if chunk:
                    results.append(chunk)
        
        return results
    
    def _search_memory(self, query_vector: List[float], n_results: int) -> List[MemoryChunk]:
        """å†…å­˜æœç´¢"""
        scored_chunks = []
        
        for chunk in self.memory_store.values():
            if chunk.embedding:
                similarity = self._cosine_similarity(query_vector, chunk.embedding)
                scored_chunks.append((similarity, chunk))
        
        # æŒ‰ç›¸ä¼¼åº¦æ’åº
        scored_chunks.sort(key=lambda x: x[0], reverse=True)
        return [chunk for _, chunk in scored_chunks[:n_results]]
    
    def _generate_embedding(self, text: str) -> List[float]:
        """ç”Ÿæˆç®€å•çš„åŸºäºå“ˆå¸Œçš„åµŒå…¥"""
        import hashlib
        
        # ä½¿ç”¨æ–‡æœ¬å“ˆå¸Œç”Ÿæˆç¡®å®šæ€§å‘é‡
        hash_val = int(hashlib.md5(text.encode('utf-8')).hexdigest(), 16)
        
        # ç”Ÿæˆå›ºå®šç»´åº¦çš„å‘é‡
        vector = []
        for i in range(self.dim):
            vector.append(math.sin(hash_val * (i + 1)) * 0.5 + 0.5)
        
        # L2å½’ä¸€åŒ–
        norm = math.sqrt(sum(v * v for v in vector)) or 1.0
        return [v / norm for v in vector]
    
    def _cosine_similarity(self, vec1: List[float], vec2: List[float]) -> float:
        """è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦"""
        if not vec1 or not vec2:
            return 0.0
        
        dot_product = sum(a * b for a, b in zip(vec1, vec2))
        norm1 = math.sqrt(sum(a * a for a in vec1))
        norm2 = math.sqrt(sum(a * a for a in vec2))
        
        if norm1 == 0 or norm2 == 0:
            return 0.0
        
        return dot_product / (norm1 * norm2)


class GraphDatabase:
    """å›¾æ•°æ®åº“æ¥å£ - æ”¯æŒNeo4jå’Œå†…å­˜å®ç°"""
    
    def __init__(self, graph_name: str, use_real_backend: bool = False):
        self.graph_name = graph_name
        self.use_real_backend = use_real_backend
        self.config = get_config().database
        
        if use_real_backend and NEO4J_AVAILABLE:
            self._init_neo4j()
        else:
            self._init_memory_backend()
    
    def _init_neo4j(self):
        """åˆå§‹åŒ–Neo4jåç«¯"""
        try:
            self.driver = GraphDatabase.driver(
                self.config.graph_uri,
                auth=(self.config.graph_user, self.config.graph_password)
            )
            self.driver.verify_connectivity()
            print(f"ğŸ”— Neo4jå›¾æ•°æ®åº“è¿æ¥æˆåŠŸ ({self.graph_name})")
        except Exception as e:
            print(f"âš ï¸ Neo4jè¿æ¥å¤±è´¥ï¼Œä½¿ç”¨å†…å­˜åç«¯: {e}")
            self._init_memory_backend()
    
    def _init_memory_backend(self):
        """åˆå§‹åŒ–å†…å­˜åç«¯"""
        self.nodes = {}
        self.edges = []
        self.driver = None
        print(f"ğŸ§  å†…å­˜å›¾æ•°æ®åº“åˆå§‹åŒ–å®Œæˆ ({self.graph_name})")
    
    def add_node(self, node: Node):
        """æ·»åŠ èŠ‚ç‚¹"""
        if self.driver:
            self._add_node_neo4j(node)
        else:
            self.nodes[node.id] = node
    
    def add_relationship(self, rel: Relationship):
        """æ·»åŠ å…³ç³»"""
        if self.driver:
            self._add_relationship_neo4j(rel)
        else:
            self.edges.append(rel)
    
    def get_node(self, node_id: str) -> Optional[Node]:
        """è·å–èŠ‚ç‚¹"""
        if self.driver:
            return self._get_node_neo4j(node_id)
        else:
            return self.nodes.get(node_id)
    
    def get_neighbors(self, node_id: str) -> List[Node]:
        """è·å–é‚»å±…èŠ‚ç‚¹"""
        if self.driver:
            return self._get_neighbors_neo4j(node_id)
        else:
            return self._get_neighbors_memory(node_id)
    
    def get_weighted_neighbors(self, node_id: str) -> List[Tuple[Node, float]]:
        """è·å–å¸¦æƒé‡çš„é‚»å±…èŠ‚ç‚¹"""
        if self.driver:
            return self._get_weighted_neighbors_neo4j(node_id)
        else:
            return self._get_weighted_neighbors_memory(node_id)
    
    # Neo4jå®ç°
    def _add_node_neo4j(self, node: Node):
        """Neo4jæ·»åŠ èŠ‚ç‚¹"""
        query = (
            f"MERGE (n:{node.label} {{id: $id}}) "
            "SET n += $properties, n.embedding = $embedding"
        )
        with self.driver.session() as session:
            session.run(query, {
                "id": node.id,
                "properties": node.properties,
                "embedding": node.embedding or []
            })
    
    def _add_relationship_neo4j(self, rel: Relationship):
        """Neo4jæ·»åŠ å…³ç³»"""
        query = (
            "MATCH (s {id: $source_id}), (t {id: $target_id}) "
            f"MERGE (s)-[r:{rel.label}]->(t) "
            "SET r += $properties, r.weight = $weight"
        )
        with self.driver.session() as session:
            session.run(query, {
                "source_id": rel.source_id,
                "target_id": rel.target_id,
                "properties": rel.properties,
                "weight": rel.weight
            })
    
    def _get_node_neo4j(self, node_id: str) -> Optional[Node]:
        """Neo4jè·å–èŠ‚ç‚¹"""
        query = "MATCH (n {id: $node_id}) RETURN n"
        with self.driver.session() as session:
            result = session.run(query, {"node_id": node_id})
            record = result.single()
            if record:
                n = record["n"]
                return Node(
                    id=n["id"],
                    label=list(n.labels)[0],
                    properties=dict(n),
                    embedding=n.get("embedding")
                )
        return None
    
    def _get_neighbors_neo4j(self, node_id: str) -> List[Node]:
        """Neo4jè·å–é‚»å±…"""
        query = "MATCH (n {id: $node_id})-[]-(neighbor) RETURN neighbor"
        neighbors = []
        with self.driver.session() as session:
            result = session.run(query, {"node_id": node_id})
            for record in result:
                n = record["neighbor"]
                neighbors.append(Node(
                    id=n["id"],
                    label=list(n.labels)[0],
                    properties=dict(n),
                    embedding=n.get("embedding")
                ))
        return neighbors
    
    def _get_weighted_neighbors_neo4j(self, node_id: str) -> List[Tuple[Node, float]]:
        """Neo4jè·å–å¸¦æƒé‡é‚»å±…"""
        query = "MATCH (n {id: $node_id})-[r]-(neighbor) RETURN neighbor, r.weight as weight"
        neighbors = []
        with self.driver.session() as session:
            result = session.run(query, {"node_id": node_id})
            for record in result:
                n = record["neighbor"]
                weight = record["weight"] or 1.0
                node = Node(
                    id=n["id"],
                    label=list(n.labels)[0],
                    properties=dict(n),
                    embedding=n.get("embedding")
                )
                neighbors.append((node, weight))
        return neighbors
    
    # å†…å­˜å®ç°
    def _get_neighbors_memory(self, node_id: str) -> List[Node]:
        """å†…å­˜è·å–é‚»å±…"""
        neighbors = []
        for edge in self.edges:
            if edge.source_id == node_id and edge.target_id in self.nodes:
                neighbors.append(self.nodes[edge.target_id])
            elif edge.target_id == node_id and edge.source_id in self.nodes:
                neighbors.append(self.nodes[edge.source_id])
        return neighbors
    
    def _get_weighted_neighbors_memory(self, node_id: str) -> List[Tuple[Node, float]]:
        """å†…å­˜è·å–å¸¦æƒé‡é‚»å±…"""
        neighbors = []
        for edge in self.edges:
            if edge.source_id == node_id and edge.target_id in self.nodes:
                neighbors.append((self.nodes[edge.target_id], edge.weight))
            elif edge.target_id == node_id and edge.source_id in self.nodes:
                neighbors.append((self.nodes[edge.source_id], edge.weight))
        return neighbors


class MultipleMemorySystems:
    """å¤šé‡è®°å¿†ç³»ç»Ÿç®¡ç†å™¨"""
    
    def __init__(self, user_id: str, use_real_backends: bool = False):
        self.user_id = user_id
        self.use_real_backends = use_real_backends
        
        print(f"ğŸ§  åˆå§‹åŒ–å¤šé‡è®°å¿†ç³»ç»Ÿ (ç”¨æˆ·: {user_id}, çœŸå®åç«¯: {use_real_backends})")
        
        # æƒ…æ™¯è®°å¿† - å‘é‡æ•°æ®åº“
        self.episodic = VectorDatabase(
            collection_name=f"{user_id}_episodic",
            use_real_backend=use_real_backends
        )
        
        # è¯­ä¹‰è®°å¿† - å›¾æ•°æ®åº“
        self.semantic = GraphDatabase(
            graph_name=f"{user_id}_semantic",
            use_real_backend=use_real_backends
        )
        
        # ç¨‹åºè®°å¿† - å›¾æ•°æ®åº“
        self.procedural = GraphDatabase(
            graph_name=f"{user_id}_procedural",
            use_real_backend=use_real_backends
        )
        
        print("âœ… å¤šé‡è®°å¿†ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")
    
    # æƒ…æ™¯è®°å¿†æ¥å£
    def add_to_episodic(self, chunk: MemoryChunk):
        """æ·»åŠ åˆ°æƒ…æ™¯è®°å¿†"""
        self.episodic.add(chunk)
    
    def search_episodic_by_vector(self, query_vector: List[float], n_results: int = 3) -> List[MemoryChunk]:
        """å‘é‡æœç´¢æƒ…æ™¯è®°å¿†"""
        return self.episodic.search(query_vector, n_results)
    
    # è¯­ä¹‰è®°å¿†æ¥å£
    def add_semantic_node(self, node: Node):
        """æ·»åŠ è¯­ä¹‰èŠ‚ç‚¹"""
        self.semantic.add_node(node)
    
    def add_semantic_relationship(self, rel: Relationship):
        """æ·»åŠ è¯­ä¹‰å…³ç³»"""
        self.semantic.add_relationship(rel)
    
    def get_semantic_node(self, node_id: str) -> Optional[Node]:
        """è·å–è¯­ä¹‰èŠ‚ç‚¹"""
        return self.semantic.get_node(node_id)
    
    def get_semantic_neighbors(self, node_id: str) -> List[Node]:
        """è·å–è¯­ä¹‰é‚»å±…"""
        return self.semantic.get_neighbors(node_id)
    
    def get_semantic_weighted_neighbors(self, node_id: str) -> List[Tuple[Node, float]]:
        """è·å–è¯­ä¹‰å¸¦æƒé‚»å±…"""
        return self.semantic.get_weighted_neighbors(node_id)
    
    # ç¨‹åºè®°å¿†æ¥å£
    def add_procedural_node(self, node: Node):
        """æ·»åŠ ç¨‹åºèŠ‚ç‚¹"""
        self.procedural.add_node(node)
    
    def add_procedural_relationship(self, rel: Relationship):
        """æ·»åŠ ç¨‹åºå…³ç³»"""
        self.procedural.add_relationship(rel)
    
    def get_procedural_node(self, node_id: str) -> Optional[Node]:
        """è·å–ç¨‹åºèŠ‚ç‚¹"""
        return self.procedural.get_node(node_id)
    
    def get_procedural_neighbors(self, node_id: str) -> List[Node]:
        """è·å–ç¨‹åºé‚»å±…"""
        return self.procedural.get_neighbors(node_id)
    
    def get_procedural_weighted_neighbors(self, node_id: str) -> List[Tuple[Node, float]]:
        """è·å–ç¨‹åºå¸¦æƒé‚»å±…"""
        return self.procedural.get_weighted_neighbors(node_id)

